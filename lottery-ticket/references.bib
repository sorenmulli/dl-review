@inproceedings{frankle2018the,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJl-b3RcF7},
}

@inproceedings{han2015learning,
author = {Han, Song and Pool, Jeff and Tran, John and Dally, William J.},
title = {Learning Both Weights and Connections for Efficient Neural Networks},
year = {2015},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1},
pages = {1135â€“1143},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'15}
}

@article{lange2020lth,
    author = {Robert Tjarko Lange},
    title = {The Lottery Ticket Hypothesis: A Survey},
    date={2020-06-27},
    journal={Rob's Homepage},
    url={https://roberttlange.github.io/posts/2020/06/lottery-ticket-hypothesis},
    urldate={2022-06-10}
}

@article{nzmora2019distiller,
  author       = {Neta Zmora and Guy Jacob and Lev Zlotnik and Bar Elharar and Gal Novik},
  title        = {Neural Network Distiller: A Python Package For DNN Compression Research},
  month        = {October},
  year         = {2019},
  url          = {https://arxiv.org/abs/1910.12232}
}

@inproceedings{bla2020state,
 author = {Blalock, Davis and Gonzalez Ortiz, Jose Javier and Frankle, Jonathan and Guttag, John},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {I. Dhillon and D. Papailiopoulos and V. Sze},
 pages = {129--146},
 title = {What is the State of Neural Network Pruning?},
 url = {https://proceedings.mlsys.org/paper/2020/file/d2ddea18f00665ce8623e36bd4e3c7c5-Paper.pdf},
 volume = {2},
 year = {2020}
}

@article{li2016filt,
  author    = {Hao Li and
               Asim Kadav and
               Igor Durdanovic and
               Hanan Samet and
               Hans Peter Graf},
  title     = {Pruning Filters for Efficient ConvNets},
  journal   = {CoRR},
  volume    = {abs/1608.08710},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.08710},
  eprinttype = {arXiv},
  eprint    = {1608.08710},
  timestamp = {Fri, 29 Mar 2019 16:37:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/LiKDSG16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{LeCun1989OptimalBD,
  title={Optimal Brain Damage},
  author={Yann LeCun and John S. Denker and Sara A. Solla},
  booktitle={NIPS},
  year={1989}
}

@article{Frankle2020LinearMC,
  title={Linear Mode Connectivity and the Lottery Ticket Hypothesis},
  author={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel M. Roy and Michael Carbin},
  journal={ArXiv},
  year={2020},
  volume={abs/1912.05671}
}

@article{Renda2020ComparingRA,
  title={Comparing Rewinding and Fine-tuning in Neural Network Pruning},
  author={Alex Renda and Jonathan Frankle and Michael Carbin},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.02389}
}

@article{You2020DrawingET,
  title={Drawing early-bird tickets: Towards more efficient training of deep networks},
  author={Haoran You and Chaojian Li and Pengfei Xu and Y. Fu and Yue Wang and Xiaohan Chen and Yingyan Lin and Zhangyang Wang and Richard Baraniuk},
  journal={ArXiv},
  year={2020},
  volume={abs/1909.11957}
}
@article{Tanaka2020PruningNN,
  title={Pruning neural networks without any data by iteratively conserving synaptic flow},
  author={Hidenori Tanaka and Daniel Kunin and Daniel L. K. Yamins and Surya Ganguli},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.05467}
}
@article{Wang2020PickingWT,
  title={Picking Winning Tickets Before Training by Preserving Gradient Flow},
  author={Chaoqi Wang and ChaoQi Wang and Guodong Zhang and Roger B. Grosse},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.07376}
}
@article{Zhang2021EfficientLT,
  title={Efficient Lottery Ticket Finding: Less Data is More},
  author={Zhenyu (Allen) Zhang and Xuxi Chen and Tianlong Chen and Zhangyang Wang},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.03225}
}
@inproceedings{Lee2019WideNN,
  title={Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent},
  author={Jaehoon Lee and Lechao Xiao and Samuel S. Schoenholz and Yasaman Bahri and Roman Novak and Jascha Sohl-Dickstein and Jascha Sohl-Dickstein},
  booktitle={NeurIPS},
  year={2019}
}
